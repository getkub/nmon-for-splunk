# macros.conf

##############
# NMON index #
##############

##### Customization ####
# In case of index name customization or spliting data into multiple indexes, you should
# copy this stanza to local/macros.conf to adapt eventtypes definition to your needs
########################

[nmon_index]
definition = index="nmon"
iseval = 0

#########################################
#	LPAR Specific definitions
#########################################

[lpar_define_conso]
definition = eval lpar_ecconso=round(((EC_User_PCT+EC_Sys_PCT+EC_Wait_PCT+EC_Idle_PCT)*entitled/100),2)\
| eval lpar_ec_pct_conso=round((((EC_User_PCT+EC_Sys_PCT+EC_Wait_PCT+EC_Idle_PCT)*entitled)/virtualCPUs),2)\
| eval lpar_vpconso=round(((VP_User_PCT+VP_Sys_PCT+VP_Wait_PCT+VP_Idle_PCT)*virtualCPUs/100),2)\
| eval lpar_vp_pct_conso=round((VP_User_PCT+VP_Sys_PCT+VP_Wait_PCT+VP_Idle_PCT),2)\
| eval pool_conso=round((poolCPUs-PoolIdle),2)\
| eval pool_pct_conso=round(((poolCPUs-PoolIdle)*poolCPUs/100),2)
iseval = 0

#########################################
#	Custom Span Macro Definition
#########################################

# Since Version 1.4.4 of Nmon App, the custom span definition has been improved to match at the lower level the nmon interval definition now incorporated in the data indexed by Splunk
# The converter adds this data in fields "interval"
# If the field is not present in data (eg. data indexed before Version 1.4.4), then the standard span time will be applied
# So, ONLY if you indexed Nmon data prior to Version 1.4.4:

# If your minimal interval data is higher (for example your minimal interval data is 5 minutes between 2 measures), then you should customized
# the macro in your local/macros.conf file
# An commented example with 5 minutes data interval is provided after the 2 standard macros used within the App 
# This will allow data indexed before Version 1.4.4 to have an adapted span definition
# It is not required if you don't have data indexed with version prior to 1.4.4 (and Python converter version prior to 1.0.4)

# The macro behind assumes that your interval between 2 measures will never be lower than 1 hour, which is a very very minimal configuration !
# If not, then you have to customize the macro on own

# The macro requires 2 arguments, the type (type of performance monitor) and hostname, both arguments can be multiple
# If multiple hostname are provided, we will assume they share the same interval value as we keep only the 1st result for performance purpose
# If multiple type are provided, they anyway always share the same interval value

#################
# CUSTOMIZATION:
#################

# Release V1.7.3: the original "inline_customspan" has been replaced for easier access with "nmon_span"
# The original macro is left for historical reasons (if some users have created their own reports or dahboards using the inline_customspan)

# If you want to set a minimal span feature that better fits your data, such as 5mn between 2 measures for example, please:
# - Copy the 2 customspan macros to your local/macros.conf
# - Edit the line:

#  | eval span=if(spanrestricted <= 20, "20s", span)\

# And replace with: (example with 5 minutes span, time unit is in seconds)

#  | eval span=if(spanrestricted <= (5*60), "5m", span)\

# Simplified version, no args

# Note with Nmon Performance update v1.6.13: The simple version uses now a "| stats count" instead of opening the index
# for the first event (| head 1), which is above 2/3x faster

[nmon_span]
definition = [ | stats count | addinfo\
| eval earliest=if(info_min_time == "0.000", info_search_time,info_min_time)\
| eval latest=if(info_max_time == "+Infinity", info_search_time,info_max_time)\
| eval searchStartTIme=strftime(earliest,"%a %d %B %Y %H:%M")\
| eval searchEndTime=strftime(latest,"%a %d %B %Y %H:%M")\
| eval Difference = (latest - earliest)\
| eval span=case(\
info_min_time == "0.000", "2m",\
Difference > (3000*24*60*60),"4d",\
Difference > (2000*24*60*60),"3d",\
Difference > (1000*24*60*60),"2d",\
Difference > (500*24*60*60),"1d",\
Difference > (333*24*60*60),"12h",\
Difference > (166*24*60*60),"8h",\
Difference > (83*24*60*60),"4h",\
Difference > (41*24*60*60),"2h",\
Difference > (916*60*60),"1h",\
Difference > (833*60*60),"55m",\
Difference > (750*60*60),"50m",\
Difference > (666*60*60),"45m",\
Difference > (583*60*60),"40m",\
Difference > (500*60*60),"35m",\
Difference > (416*60*60),"30m",\
Difference > (333*60*60),"25m",\
Difference > (250*60*60),"20m",\
Difference > (166*60*60),"15m",\
Difference > (83*60*60),"10m",\
Difference > (66*60*60),"5m",\
Difference > (50*60*60),"4m",\
Difference > (33*60*60),"3m",\
Difference > (16*60*60),"2m",\
Difference > (8*60*60),"1m",\
Difference <= (8*60*60),"1m"\
)\
| eval spanrestricted=case(\
info_min_time == "0.000", 2*60,\
Difference > (916*60*60),60*60,\
Difference > (833*60*60),55*60,\
Difference > (750*60*60),50*60,\
Difference > (666*60*60),45*60,\
Difference > (583*60*60),40*60,\
Difference > (500*60*60),35*60,\
Difference > (416*60*60),30*60,\
Difference > (333*60*60),25*60,\
Difference > (250*60*60),20*60,\
Difference > (166*60*60),15*60,\
Difference > (83*60*60),10*60,\
Difference > (66*60*60),5*60,\
Difference > (50*60*60),4*60,\
Difference > (33*60*60),180,\
Difference > (16*60*60),120,\
Difference > (8*60*60),60,\
Difference <= (8*60*60),60\
)\
| eval span=case(spanrestricted < interval, interval, spanrestricted >= interval, span, isnull(interval), span)\
| eval span=if(spanrestricted <= 60, "1m", span)\
| return span ]
iseval = 0

[inline_customspan]
definition = [ | stats count | addinfo\
| eval earliest=if(info_min_time == "0.000", info_search_time,info_min_time)\
| eval latest=if(info_max_time == "+Infinity", info_search_time,info_max_time)\
| eval searchStartTIme=strftime(earliest,"%a %d %B %Y %H:%M")\
| eval searchEndTime=strftime(latest,"%a %d %B %Y %H:%M")\
| eval Difference = (latest - earliest)\
| eval span=case(\
info_min_time == "0.000", "2m",\
Difference > (3000*24*60*60),"4d",\
Difference > (2000*24*60*60),"3d",\
Difference > (1000*24*60*60),"2d",\
Difference > (500*24*60*60),"1d",\
Difference > (333*24*60*60),"12h",\
Difference > (166*24*60*60),"8h",\
Difference > (83*24*60*60),"4h",\
Difference > (41*24*60*60),"2h",\
Difference > (916*60*60),"1h",\
Difference > (833*60*60),"55m",\
Difference > (750*60*60),"50m",\
Difference > (666*60*60),"45m",\
Difference > (583*60*60),"40m",\
Difference > (500*60*60),"35m",\
Difference > (416*60*60),"30m",\
Difference > (333*60*60),"25m",\
Difference > (250*60*60),"20m",\
Difference > (166*60*60),"15m",\
Difference > (83*60*60),"10m",\
Difference > (66*60*60),"5m",\
Difference > (50*60*60),"4m",\
Difference > (33*60*60),"3m",\
Difference > (16*60*60),"2m",\
Difference > (8*60*60),"1m",\
Difference <= (8*60*60),"1m"\
)\
| eval spanrestricted=case(\
info_min_time == "0.000", 2*60,\
Difference > (916*60*60),60*60,\
Difference > (833*60*60),55*60,\
Difference > (750*60*60),50*60,\
Difference > (666*60*60),45*60,\
Difference > (583*60*60),40*60,\
Difference > (500*60*60),35*60,\
Difference > (416*60*60),30*60,\
Difference > (333*60*60),25*60,\
Difference > (250*60*60),20*60,\
Difference > (166*60*60),15*60,\
Difference > (83*60*60),10*60,\
Difference > (66*60*60),5*60,\
Difference > (50*60*60),4*60,\
Difference > (33*60*60),180,\
Difference > (16*60*60),120,\
Difference > (8*60*60),60,\
Difference <= (8*60*60),60\
)\
| eval span=case(spanrestricted < interval, interval, spanrestricted >= interval, span, isnull(interval), span)\
| eval span=if(spanrestricted <= 60, "1m", span)\
| return span ]
iseval = 0


# Baseline macro, uses a minimal span of 5m to match the Baseline span

# Note with Nmon Performance update v1.6.13: The simple version uses now a "| stats count" instead of opening the index
# for the first event (| head 1), which is above 2/3x faster

[baseline_span]
definition = [ | stats count | addinfo\
| eval earliest=if(info_min_time == "0.000", info_search_time,info_min_time)\
| eval latest=if(info_max_time == "+Infinity", info_search_time,info_max_time)\
| eval searchStartTIme=strftime(earliest,"%a %d %B %Y %H:%M")\
| eval searchEndTime=strftime(latest,"%a %d %B %Y %H:%M")\
| eval Difference = (latest - earliest)\
| eval span=case(\
info_min_time == "0.000", "2m",\
Difference > (3000*24*60*60),"4d",\
Difference > (2000*24*60*60),"3d",\
Difference > (1000*24*60*60),"2d",\
Difference > (500*24*60*60),"1d",\
Difference > (333*24*60*60),"12h",\
Difference > (166*24*60*60),"8h",\
Difference > (83*24*60*60),"4h",\
Difference > (41*24*60*60),"2h",\
Difference > (916*60*60),"1h",\
Difference > (833*60*60),"55m",\
Difference > (750*60*60),"50m",\
Difference > (666*60*60),"45m",\
Difference > (583*60*60),"40m",\
Difference > (500*60*60),"35m",\
Difference > (416*60*60),"30m",\
Difference > (333*60*60),"25m",\
Difference > (250*60*60),"20m",\
Difference > (166*60*60),"15m",\
Difference > (83*60*60),"10m",\
Difference > (8*60*60),"5m",\
Difference <= (8*60*60),"5m"\
)\
| eval spanrestricted=case(\
info_min_time == "0.000", 2*60,\
Difference > (916*60*60),60*60,\
Difference > (833*60*60),55*60,\
Difference > (750*60*60),50*60,\
Difference > (666*60*60),45*60,\
Difference > (583*60*60),40*60,\
Difference > (500*60*60),35*60,\
Difference > (416*60*60),30*60,\
Difference > (333*60*60),25*60,\
Difference > (250*60*60),20*60,\
Difference > (166*60*60),15*60,\
Difference > (83*60*60),10*60,\
Difference > (8*60*60),5*60,\
Difference <= (8*60*60),5*60\
)\
| eval span=case(spanrestricted < interval, interval, spanrestricted >= interval, span, isnull(interval), span)\
| eval span=if(spanrestricted <= 60, "5m", span)\
| return span ]
iseval = 0

###############################################
#	Macro used in Compare interface
###############################################

[eval_compare]
definition = eval Evolution_usage=((usage_period2-usage_period1)/usage_period1)*100 | eval Evolution_usage=round(Evolution_usage,3)\
| eval Delta_usage=round((usage_period2-usage_period1),3)\
| eval Evolution_pct_usage=case(isnotnull(pct_usage_period1), ((pct_usage_period2-pct_usage_period1)/pct_usage_period1)*100 ) | eval Evolution_pct_usage=round(Evolution_pct_usage,3)\
| eval Delta_pct_usage=round((pct_usage_period2-pct_usage_period1),3)\
| fields hostname,usage_period1,usage_period2,Delta_usage,Evolution_usage,*\
| rename Evolution_usage As "Evolution_usage (%)"\
| rename Evolution_pct_usage As "Evolution_pct_usage (%)"\
| eval range=case(\
usage_period1==usage_period2, 0, usage_period1<usage_period2, 2, usage_period1>usage_period2, 4,\
pct_usage_period1==pct_usage_period2, 0, pct_usage_period1<pct_usage_period2, 2, pct_usage_period1>pct_usage_period2, 4)\
| rangemap field=range equal=0-1 increase=2-3 decrease=4-5 default=no\
| eval usage_period1=round(usage_period1,3)\
| eval usage_period2=round(usage_period2,3)
iseval = 0


###############################################
#	TimeRange overwrite
###############################################

# Manipulate the given timerange to force earliest and latest to be full days

[timerange_overwrite(2)]
args = indexvalue,sourcetypevalue
definition = [ search index=$indexvalue$ sourcetype=$sourcetypevalue$ | head 1 | addinfo\
| eval earliest=relative_time(info_min_time, "@d")\
| eval latest=relative_time(info_max_time, "+1d@d") | return earliest,latest ]
iseval = 0


###################################
# 	Index Statistics
###################################

[indexes_datestats]

definition = metadata type=sourcetypes `nmon_index` | setfields `nmon_index` | eval "First Event"=strftime(firstTime,"%d %b %y, %Hh%M") | eval "Last Event"=strftime(lastTime,"%d %b %y, %Hh%M")\
| fields index,sourcetype,*Event
iseval = 0

###################################
# 	Eval Memory
###################################

[MEM_eval]
definition = eval Real_used_MB=round((Real_total_MB-Real_free_MB),1)\
| eval Virtual_total_MB=round((Virtual_total_MB),1)\
| eval Virtual_used_MB=round((Virtual_total_MB-Virtual_free_MB),1)\
| eval memused=round((memtotal-memfree),1)\
| eval swapused=round((swaptotal-swapfree),1)\
| eval Real_used_PCT=round(((Real_used_MB/Real_total_MB)*100),1)\
| eval Virtual_used_PCT=round(((Virtual_used_MB/Virtual_total_MB)*100),1)\
| eval memfree_PCT=round(((memfree/memtotal)*100),1)\
| eval memused_PCT=round(((memused/memtotal)*100),1)\
| eval swapfree_PCT=round(((swapfree/swaptotal)*100),1)\
| eval swapused_PCT=round(((swapused/swaptotal)*100),1)\
| stats \
max(Real_total_MB) As Real_total_MB, max(Real_used_MB) As Real_used_MB,\
max(memtotal) As memtotal, max(memused) As memused,\
max(Virtual_total_MB) As Virtual_total_MB, max(Virtual_used_MB) As Virtual_used_MB, \
max(swaptotal) As swaptotal, max(swapused) As swapused\
max(Real_Free_PCT) As Real_Free_PCT,\
max(memfree_PCT) As memfree_PCT,\
max(Virtual_free_PCT) As Virtual_free_PCT,\
max(swapfree_PCT) As swapfree_PCT,\
max(Real_used_PCT) As Real_used_PCT,\
max(memused_PCT) As memused_PCT,\
max(Virtual_used_PCT) As Virtual_used_PCT,\
max(swapused_PCT) As swapused_PCT,\
max(buffers) As buffers, max(cached) As cached, max(inactive) As inactive\
by _time,hostname\
| eval Real_total_MB=if(isnotnull(Real_total_MB),Real_total_MB,memtotal)\
| eval Real_used_MB=if(isnotnull(Real_used_MB),Real_used_MB,memused)\
| eval Virtual_total_MB=if(isnotnull(Virtual_total_MB),Virtual_total_MB,swaptotal) \
| eval Virtual_used_MB=if(isnotnull(Virtual_used_MB),Virtual_used_MB,swapused)\
| eval Real_Free_PCT=if(isnotnull(Real_Free_PCT),Real_Free_PCT,memfree_PCT)\
| eval Virtual_free_PCT=if(isnotnull(Virtual_free_PCT),Virtual_free_PCT,swapfree_PCT)\
| eval Real_used_PCT=if(isnotnull(Real_used_PCT),Real_used_PCT,memused_PCT)\
| eval Virtual_used_PCT=if(isnotnull(Virtual_used_PCT),Virtual_used_PCT,swapused_PCT)
iseval = 0

[MEM_allOS]
definition = eval Real_used_MB=round((Real_total_MB-Real_free_MB),1)\
| eval Virtual_total_MB=round((Virtual_total_MB),1)\
| eval Virtual_used_MB=round((Virtual_total_MB-Virtual_free_MB),1)\
| eval memused=round((memtotal-memfree),1)\
| eval swapused=round((swaptotal-swapfree),1)\
| eval Real_used_PCT=round(((Real_used_MB/Real_total_MB)*100),1)\
| eval Virtual_used_PCT=round(((Virtual_used_MB/Virtual_total_MB)*100),1)\
| eval memfree_PCT=round(((memfree/memtotal)*100),1)\
| eval memused_PCT=round(((memused/memtotal)*100),1)\
| eval swapfree_PCT=round(((swapfree/swaptotal)*100),1)\
| eval swapused_PCT=round(((swapused/swaptotal)*100),1)\
| eval Real_total_MB=if(isnotnull(Real_total_MB),Real_total_MB,memtotal)\
| eval Real_used_MB=if(isnotnull(Real_used_MB),Real_used_MB,memused)\
| eval Virtual_total_MB=if(isnotnull(Virtual_total_MB),Virtual_total_MB,swaptotal) \
| eval Virtual_used_MB=if(isnotnull(Virtual_used_MB),Virtual_used_MB,swapused)\
| eval Real_Free_PCT=if(isnotnull(Real_Free_PCT),Real_Free_PCT,memfree_PCT)\
| eval Virtual_free_PCT=if(isnotnull(Virtual_free_PCT),Virtual_free_PCT,swapfree_PCT)\
| eval Real_used_PCT=if(isnotnull(Real_used_PCT),Real_used_PCT,memused_PCT)\
| eval Virtual_used_PCT=if(isnotnull(Virtual_used_PCT),Virtual_used_PCT,swapused_PCT)
iseval = 0

# Used to simplify datamodel seearches for Linux Memory interface
[memory_linux_dm]
definition = max("MEM.mem_free") AS mem_free_MB max("MEM.mem_free_effective") AS mem_free_effective_MB max("MEM.mem_free_PCT") AS mem_free_PCT max("MEM.mem_free_effective_PCT") AS mem_free_effective_PCT\
max("MEM.mem_used") AS mem_used_MB max("MEM.mem_used_effective") AS mem_used_effective_MB max("MEM.mem_used_PCT") AS mem_used_PCT max("MEM.mem_used_effective_PCT") AS mem_used_effective_PCT\
max("MEM.active") AS mem_active_MB, max("MEM.active_PCT") AS mem_active_PCT, max("MEM.inactive") AS mem_inactive_MB, max("MEM.inactive_PCT") AS mem_inactive_PCT\
max("MEM.buffers") AS mem_buffers_MB, max("MEM.buffers_PCT") AS mem_buffers_PCT, max("MEM.cached") AS mem_cached_MB, max("MEM.cached_PCT") AS mem_cached_PCT\
max("MEM.memtotal") AS mem_total_MB\
max("MEM.swap_free") AS swap_free_MB, max("MEM.swap_free_effective") AS swap_free_effective_MB, max("MEM.swap_free_PCT") AS swap_free_PCT, max("MEM.swap_free_effective_PCT") AS swap_free_effective_PCT,\
max("MEM.swap_used") AS swap_used_MB, max("MEM.swap_used_effective") AS swap_used_effective_MB, max("MEM.swap_used_PCT") AS swap_used_PCT, max("MEM.swap_used_effective_PCT") AS swap_used_effective_PCT,\
max("MEM.swapcached") AS swap_cached_MB, max("MEM.swapcached_PCT") AS swap_cached_PCT,\
max("MEM.swaptotal") AS swap_total_MB
iseval = 0

# Used to simplify datamodel seearches for Linux Memory interface
[memory_linux_dm(1)]
args = statsmode
definition = $statsmode$("MEM.mem_free") AS mem_free_MB $statsmode$("MEM.mem_free_effective") AS mem_free_effective_MB $statsmode$("MEM.mem_free_PCT") AS mem_free_PCT $statsmode$("MEM.mem_free_effective_PCT") AS mem_free_effective_PCT\
$statsmode$("MEM.mem_used") AS mem_used_MB $statsmode$("MEM.mem_used_effective") AS mem_used_effective_MB $statsmode$("MEM.mem_used_PCT") AS mem_used_PCT $statsmode$("MEM.mem_used_effective_PCT") AS mem_used_effective_PCT\
$statsmode$("MEM.active") AS mem_active_MB, $statsmode$("MEM.active_PCT") AS mem_active_PCT, $statsmode$("MEM.inactive") AS mem_inactive_MB, $statsmode$("MEM.inactive_PCT") AS mem_inactive_PCT\
$statsmode$("MEM.buffers") AS mem_buffers_MB, $statsmode$("MEM.buffers_PCT") AS mem_buffers_PCT, $statsmode$("MEM.cached") AS mem_cached_MB, $statsmode$("MEM.cached_PCT") AS mem_cached_PCT\
$statsmode$("MEM.memtotal") AS mem_total_MB\
$statsmode$("MEM.swap_free") AS swap_free_MB, $statsmode$("MEM.swap_free_effective") AS swap_free_effective_MB, $statsmode$("MEM.swap_free_PCT") AS swap_free_PCT, $statsmode$("MEM.swap_free_effective_PCT") AS swap_free_effective_PCT,\
$statsmode$("MEM.swap_used") AS swap_used_MB, $statsmode$("MEM.swap_used_effective") AS swap_used_effective_MB, $statsmode$("MEM.swap_used_PCT") AS swap_used_PCT, $statsmode$("MEM.swap_used_effective_PCT") AS swap_used_effective_PCT,\
$statsmode$("MEM.swapcached") AS swap_cached_MB, $statsmode$("MEM.swapcached_PCT") AS swap_cached_PCT,\
$statsmode$("MEM.swaptotal") AS swap_total_MB
iseval = 0


###################################
# 	Prediction Manual Interact
###################################

[predict_manualinteract(2)]
args = selfperiod,selfvalue
definition = eval Predict=if(_time>if("$period$" == "now", now(),strptime("$period$", "%m/%d/%Y")),Predict+$selfvalue$,Predict)\
| eval low=if(_time>if("$period$" == "now", now(),strptime("$period$", "%m/%d/%Y")),low+$selfvalue$,low)\
| eval high=if(_time>if("$period$" == "now", now(),strptime("$period$", "%m/%d/%Y")),high+$selfvalue$,high)
iseval = 0


#################################################
#																#
#					NMON CONFIG SECTION					#
#																#
#################################################

# Rex common to all OS

[nmon_config_common_rex]
definition = rex "(?i),version,(?P<nmon_version>.+)"\
| rex "(?i),command,(?P<nmon_command>.+)"\
| rex "(?i),OS,(?P<OS>[^,]+)"\
| rex "AAA,cpus,(?P<cpu_cores_position1>\d+)"\
| rex "AAA,cpus,\d+,(?P<cpu_cores_position2>\d+)"
iseval = 0

# AIX Specific

[nmon_config_AIX_rex]
definition = rex "AAA,AIX,(?P<AIX_LEVEL>.+)"\
| rex "BBB.+,[0-9].+,lparstat.+,\"Online\sVirtual\sCPUs\s+\:\s(?P<AIX_virtualcpus>\d+)\""\
| rex "BBB.+,[0-9].+,online\sMemory,(?P<AIX_memory_MB>\d+)"\
| rex "BBB.+,[0-9].+,lsconf,\"\s+Total\sPaging\sSpace:\s(?P<AIX_pagingspace_MB>\d+)"\
| rex "BBB.+,[0-9].+,lsconf,\"Processor\sImplementation\sMode:\s(?P<AIX_processor_mode>.+\w)\""\
| rex "BBB.+,[0-9].+,lsconf,\"Processor\sClock\sSpeed:\s(?P<AIX_processor_clockspeed>.+\w)\""\
| rex "BBB.+,[0-9].+,lsconf,\"CPU\sType:\s(?P<AIX_cpu_type>.+\w)\""\
| rex "BBB.+,[0-9].+,lsconf,\"Kernel\sType:\s(?P<AIX_kernel_type>.+\w)\""\
| rex "BBB.+,[0-9].+,lsconf,\"Platform\sFirmware\slevel:\s(?P<AIX_plateform_firmware_level>.+\w)\""\
| rex "BBB.+,[0-9].+,lsconf,\"Machine\sSerial\sNumber:\s(?P<AIX_Machine_SerialNumber>.+)\""\
| rex "AAA,SerialNumber,(?P<AIX_alt_Machine_SerialNumber>\w+)"\
| eval AIX_Machine_SerialNumber=if(isnotnull(AIX_Machine_SerialNumber), AIX_Machine_SerialNumber, AIX_alt_Machine_SerialNumber)\
| rex "BBB.+,[0-9].+,lparstat.+,\"Shared\sPool\sID\s+\:\s(?P<AIX_PoolID>.+)\""\
| eval AIX_PoolID=if(AIX_PoolID=="-","N/A" ,AIX_PoolID)\
| rex "BBB.+,[0-9].+,lparstat.+,\"Maximum\sPhysical\sCPUs\sin\ssystem\s+\:\s(?P<AIX_system_installed_CPUs>.+)\""\
| rex "BBB.+,[0-9].+,lparstat.+,\"Active\sPhysical\sCPUs\sin\ssystem\s+\:\s(?P<AIX_system_active_CPUs>.+)\""\
| rex "BBB.+,[0-9].+,lparstat.+,\"Active\sCPUs\sin\sPool\s+\:\s(?P<AIX_PoolCPUs>.+)\""\
| eval AIX_PoolCPUs=if(AIX_PoolCPUs=="-","N/A" ,AIX_PoolCPUs)\
| rex "BBB.+,[0-9].+,lparstat.+,\"Entitled\sCapacity\s+\:\s(?P<AIX_entitled>.+)\""\
| rex "BBB.+,[0-9].+,lsconf,\"Processor\sType:\s(?P<AIX_processor>.+\w)\""\
| strcat AIX_virtualcpus " / " cpu_cores_position2 cpu_cores_combo\
| eval AIX_logicalcores=if(isnotnull(cpu_cores_position2), cpu_cores_position2, cpu_cores_position1)
iseval = 0

# Linux specific

[nmon_config_Linux_rex]
definition = rex "AAA,OS,Linux,(?P<Linux_LEVEL>.+)"\
| rex "BBB.+,[0-9].+cpuinfo,.+model\sname.+:\s+(?P<Linux_processor>.+)\""\
| rex "BBB.+,[0-9].+,.+etc+.release,\"(?P<Linux_distribution>.+)\""\
| rex "BBB.+,[0-9].+,lsb\_release,\"Release:\s+(?P<Linux_version>.+)\""\
| rex "BBB.+,[0-9].+,.proc.meminfo,\"MemTotal:\s+(?P<Linux_memory_kB>\d+)" | eval Linux_memory_MB=round(Linux_memory_kB/1024,0)\
| rex "BBB.+,[0-9].+,.proc.meminfo,\"SwapTotal:\s+(?P<Linux_swap_kB>\d+)" | eval Linux_swap_MB=round(Linux_swap_kB/1024,0)\
| rex "AAA,OS,Linux,(?P<Linux_kernelversion>\d+.\d+).+,#"\
| rex "AAA,OS,Linux,(?P<Linux_kernel>.+),#"\
| rex "AAA,OS,Linux,(?P<Linux_fullkernel>.+)"
iseval = 0

# Solaris specific

[nmon_config_Solaris_rex]
definition = rex "AAA,OS,Solaris,(?P<Solaris_LEVEL>.+)"\
| rex "AAA,OS,Solaris,.+,(?P<Solaris_kernel>.+),.+,.+"\
| rex "AAA,OS,Solaris,(?P<Solaris_sunOS_version>.+),.+,.+,.+"\
| rex "BBB.+,[0-9].+,.+etc+.release,\"\s+(?P<Solaris_version>.+)\""\
| rex "BBB.+,[0-9].+psrinfo\s\-pv,\"\s+(?P<Solaris_processor>.+\w)\""\
| rex "BBB.+,[0-9].+psrinfo\s\-pv,.+clock\s(?P<Solaris_processor_clockspeed>.+)\)\""
iseval = 0



###################################
# 	Final macros used for inventory data retrieve
###################################

[nmon_config]
definition = `nmon_index` sourcetype=nmon_config\
| rex "(?i),host,(?P<hostname>.+)"\
| `nmon_config_common_rex`\
| `nmon_config_AIX_rex`\
| `nmon_config_Linux_rex`\
| `nmon_config_Solaris_rex`\
| eval OStype=case(OS == "Linux", "Linux", OS == "Solaris", "Solaris", isnotnull(AIX_LEVEL), "AIX")\
| eval OS_Level=case(isnotnull(AIX_LEVEL), AIX_LEVEL, isnotnull(Solaris_version), Solaris_version, isnotnull(Linux_distribution), Linux_distribution)\
| eval cpu_cores=if(isnotnull(AIX_virtualcpus), cpu_cores_combo, cpu_cores_position1)\
| eval Processor=case(isnotnull(AIX_processor), AIX_processor, isnotnull(Solaris_processor), Solaris_processor, isnotnull(Linux_processor), Linux_processor)
iseval = 0



# Used in addition with the command: `nmon_index` sourcetype=nmon_config | rex "(?i),host,(?<hostname>.+)" | search $hostname$" in Nmon_Summary
# to optimize time treatment

[nmon_config_rex]
definition = `nmon_config_common_rex`\
| `nmon_config_AIX_rex`\
| `nmon_config_Linux_rex`\
| `nmon_config_Solaris_rex`\
| eval OStype=case(OS == "Linux", "Linux", OS == "Solaris", "Solaris", isnotnull(AIX_LEVEL), "AIX")\
| eval OS_Level=case(isnotnull(AIX_LEVEL), AIX_LEVEL, isnotnull(Solaris_version), Solaris_version, isnotnull(Linux_distribution), Linux_distribution)\
| eval cpu_cores=if(isnotnull(AIX_virtualcpus), cpu_cores_combo, cpu_cores_position1)\
| eval Processor=case(isnotnull(AIX_processor), AIX_processor, isnotnull(Solaris_processor), Solaris_processor, isnotnull(Linux_processor), Linux_processor)
iseval = 0


# Called by User Interfaces to filter OS list based on type of OS

[nmon_inventory]
definition = | inputlookup nmon_inventory
iseval = 0


###################################
# 	Custom Span definition for Application Statistics Django View
###################################

[internal_table_stats_span]
definition = [ search index=_internal | head 1 | addinfo\
| eval earliest=if(info_min_time == "0.000", info_search_time,info_min_time)\
| eval latest=if(info_max_time == "+Infinity", info_search_time,info_max_time)\
| eval searchStartTIme=strftime(earliest,"%a %d %B %Y %H:%M")\
| eval searchEndTime=strftime(latest,"%a %d %B %Y %H:%M")\
| eval Difference = (latest - earliest)\
| eval span=case(\
Difference > (12*31*24*60*60),"1y",\
Difference > (31*24*60*60),"1m",\
Difference > (24*60*60),"1d",\
Difference <= (24*60*60),"1h"\
)\
| return span ]
iseval = 0


#####################
#	FILTER TIME		#
#####################

[No_Filter]
definition = eval local_time=strftime(_time, "%H:%M")
iseval = 0

[Day_BusinessDays_8h-19h]
definition = eval local_time=strftime(_time, "%H:%M") | search (local_time>="08:00" AND local_time<="19:00") AND (date_wday!="sunday" date_wday!="saturday")
iseval = 0

[Day_WeekEnd_8h-19h]
definition = eval local_time=strftime(_time, "%H:%M") | search (local_time>="08:00" AND local_time<="19:00") AND (date_wday="sunday" OR date_wday="saturday")
iseval = 0

[Day_AllDays_8h-19h]
definition = eval local_time=strftime(_time, "%H:%M") | search (local_time>="08:00" AND local_time<="19:00")
iseval = 0

[Night_BusinessDays_19h-8h]
definition = eval local_time=strftime(_time, "%H:%M") | search (local_time>="19:00" AND local_time<="23:59") OR (local_time>="00:00" AND local_time<="08:00") AND (date_wday!="sunday" date_wday!="saturday")
iseval = 0

[Night_WeekEnd_19h-8h]
definition = eval local_time=strftime(_time, "%H:%M") | search (local_time>="19:00" AND local_time<="23:59") OR (local_time>="00:00" AND local_time<="08:00") AND (date_wday="sunday" OR date_wday="saturday")
iseval = 0

[Night_AllDays_19h-8h]
definition = eval local_time=strftime(_time, "%H:%M") | search (local_time>="19:00" AND local_time<="23:59") OR (local_time>="00:00" AND local_time<="08:00")
iseval = 0

# Data Model Macros

[No_Filter(1)]
args = datamodel
definition =($datamodel$.date_wday=*) ($datamodel$.local_time=*)
iseval = 0

[Day_BusinessDays_8h-19h(1)]
args = datamodel
definition = ($datamodel$.date_wday!=saturday AND $datamodel$.date_wday!=sunday) ($datamodel$.local_time>=0800 AND $datamodel$.local_time<=1900)
iseval = 0

[Day_WeekEnd_8h-19h(1)]
args = datamodel
definition = ($datamodel$.date_wday=saturday OR $datamodel$.date_wday=sunday) ($datamodel$.local_time>=0800 AND $datamodel$.local_time<=1900)
iseval = 0

[Day_AllDays_8h-19h(1)]
args = datamodel
definition = ($datamodel$.date_wday=*) ($datamodel$.local_time>=0800 AND $datamodel$.local_time<=1900)
iseval = 0

[Night_BusinessDays_19h-8h(1)]
args = datamodel
definition = ($datamodel$.date_wday!=saturday AND $datamodel$.date_wday!=sunday) ($datamodel$.local_time>=1900 OR $datamodel$.local_time<=0800)
iseval = 0

[Night_WeekEnd_19h-8h(1)]
args = datamodel
definition = ($datamodel$.date_wday=saturday OR $datamodel$.date_wday=sunday) ($datamodel$.local_time>=1900 OR $datamodel$.local_time<=0800)
iseval = 0

[Night_AllDays_19h-8h(1)]
args = datamodel
definition = ($datamodel$.date_wday=*) ($datamodel$.local_time>=1900 OR $datamodel$.local_time<=0800)
iseval = 0

####################################################
#																	#
#					NMON PROCESSING SECTION					#
#																	#
####################################################

[nmon_processing]
definition = `nmon_index` sourcetype=nmon_processing
iseval = 0

[nmon_processing_stats]
definition = `nmon_processing`\
| eval size_KB=round((size_in_bytes/1000),2)\
| eval size_MB=round((size_in_bytes/1000/1000),2)\
| stats\
min(nbr_lines) As min_nbr_lines, avg(nbr_lines) As avg_nbr_lines, max(nbr_lines) As max_nbr_lines, sum(nbr_lines) As sum_nbr_lines,\
min(size_KB) As min_size_KB, avg(size_KB) As avg_size_KB, max(size_KB) As max_size_KB, sum(size_KB) As sum_size_KB,\
min(size_MB) As min_size_MB, avg(size_MB) As avg_size_MB, max(size_MB) As max_size_MB, sum(size_MB) As sum_size_MB,\
min(elapsed_in_seconds) As min_elapsed_in_seconds, avg(elapsed_in_seconds) As avg_elapsed_in_seconds, max(elapsed_in_seconds) As max_elapsed_in_seconds, sum(elapsed_in_seconds) As sum_elapsed_in_seconds\
| eval sum_nbr_lines_in_millions=round((sum_nbr_lines/1000/1000),2)\
| eval sum_size_GB=round((sum_size_KB/1000/1000),2)\
| eval sum_elapsed=tostring(sum_elapsed_in_seconds,"duration")\
| eval avg_nbr_lines=round(avg_nbr_lines,0)\
| eval avg_size_MB=round(avg_size_MB,2)\
| eval avg_elapsed_in_seconds=round(avg_elapsed_in_seconds,2)
iseval = 0

[nmon_processing_stats_by_time]
definition = `nmon_processing`\
| eval size_KB=round((size_in_bytes/1000),2)\
| eval size_MB=round((size_in_bytes/1000/1000),2)\
| stats\
min(nbr_lines) As min_nbr_lines, avg(nbr_lines) As avg_nbr_lines, max(nbr_lines) As max_nbr_lines, sum(nbr_lines) As sum_nbr_lines,\
min(size_KB) As min_size_KB, avg(size_KB) As avg_size_KB, max(size_KB) As max_size_KB, sum(size_KB) As sum_size_KB,\
min(size_MB) As min_size_MB, avg(size_MB) As avg_size_MB, max(size_MB) As max_size_MB, sum(size_MB) As sum_size_MB,\
min(elapsed_in_seconds) As min_elapsed_in_seconds, avg(elapsed_in_seconds) As avg_elapsed_in_seconds, max(elapsed_in_seconds) As max_elapsed_in_seconds, sum(elapsed_in_seconds) As sum_elapsed_in_seconds by _time\
| eval sum_nbr_lines_in_millions=round((sum_nbr_lines/1000/1000),2)\
| eval sum_size_GB=round((sum_size_KB/1000/1000),2)\
| eval avg_nbr_lines=round(avg_nbr_lines,0)\
| eval avg_size_MB=round(avg_size_MB,2)\
| eval avg_elapsed_in_seconds=round(avg_elapsed_in_seconds,2)
iseval = 0


####################################################
#																	#
#		macros used in views with tstats					#
#																	#
####################################################

# these macro will reduce the code length for the use of Data model tstats search in views

[CPU_ALL(1)]
args = statsmode
definition = $statsmode$("CPU.cpu_PCT") AS CPU.cpu_PCT,\
$statsmode$("CPU.Idle_PCT") AS CPU.Idle_PCT,\
$statsmode$("CPU.Sys_PCT") AS CPU.Sys_PCT,\
$statsmode$("CPU.User_PCT") AS CPU.User_PCT,\
$statsmode$("CPU.Wait_PCT") AS CPU.Wait_PCT
iseval = 0

[CPU_ALL_rename]
definition = rename CPU.cpu_PCT AS "CPU %", CPU.Idle_PCT AS "Idle %", CPU.Sys_PCT AS "Sys %", CPU.User_PCT AS "User %", CPU.Wait_PCT AS "Wait %"
iseval = 0

[LPAR(1)]
args = statsmode
definition = $statsmode$("CPU.lpar_vp_usage") AS CPU.lpar_vp_usage,\
$statsmode$("CPU.LPAR.lpar_vp_PCT_usage") AS CPU.LPAR.lpar_vp_PCT_usage,\
$statsmode$("CPU.LPAR.lpar_ec_usage") AS CPU.LPAR.lpar_ec_usage,\
$statsmode$("CPU.LPAR.lpar_ec_PCT_usage") AS CPU.LPAR.lpar_ec_PCT_usage,\
max("CPU.entitled") AS CPU.entitled,\
max("CPU.virtualCPUs") AS CPU.virtualCPUs
iseval = 0

[LPAR_rename]
definition = rename CPU.lpar_vp_usage AS "VP usage", CPU.LPAR.lpar_vp_PCT_usage AS "VP % usage", CPU.LPAR.lpar_ec_usage AS "EC usage", CPU.LPAR.lpar_ec_PCT_usage AS "EC % usage", CPU.entitled AS "Entitled", CPU.virtual_cpus AS "Virtual CPUs"
iseval = 0

[NFSSVRV4(1)]
args = statsmode
definition = $statsmode$(NFS.op0-unused),$statsmode$(NFS.op1-unused),$statsmode$(NFS.op2-future),$statsmode$(NFS.access),$statsmode$(NFS.close),$statsmode$(NFS.commit),$statsmode$(NFS.create),\
$statsmode$(NFS.delegpurge),$statsmode$(NFS.delegreturn),$statsmode$(NFS.getattr),$statsmode$(NFS.getfh),$statsmode$(NFS.link),$statsmode$(NFS.lock),$statsmode$(NFS.lockt),\
$statsmode$(NFS.locku),$statsmode$(NFS.lookup),$statsmode$(NFS.lookup_root),$statsmode$(NFS.nverify),$statsmode$(NFS.open),$statsmode$(NFS.openattr),$statsmode$(NFS.open_conf),\
$statsmode$(NFS.open_dgrd),$statsmode$(NFS.putfh),$statsmode$(NFS.putpubfh),$statsmode$(NFS.putrootfh),$statsmode$(NFS.read),$statsmode$(NFS.readdir),$statsmode$(NFS.readlink),\
$statsmode$(NFS.remove),$statsmode$(NFS.rename),$statsmode$(NFS.renew),$statsmode$(NFS.restorefh),$statsmode$(NFS.savefh),$statsmode$(NFS.secinfo),$statsmode$(NFS.setattr),\
$statsmode$(NFS.setcltid),$statsmode$(NFS.setcltidconf),$statsmode$(NFS.verify),$statsmode$(NFS.write),$statsmode$(NFS.rellockowner)
iseval = 0

[NFSSVRV3(1)]
args = statsmode
definition = $statsmode$(NFS.null),$statsmode$(NFS.getattr),$statsmode$(NFS.setattr),$statsmode$(NFS.lookup),$statsmode$(NFS.access),\
$statsmode$(NFS.readlink),$statsmode$(NFS.read),$statsmode$(NFS.write),$statsmode$(NFS.create),$statsmode$(NFS.mkdir),$statsmode$(NFS.symlink),\
$statsmode$(NFS.mknod),$statsmode$(NFS.remove),$statsmode$(NFS.rmdir),$statsmode$(NFS.rename),$statsmode$(NFS.link),$statsmode$(NFS.readdir),\
$statsmode$(NFS.readdirplus),$statsmode$(NFS.fsstat),$statsmode$(NFS.fsinfo),$statsmode$(NFS.pathconf),$statsmode$(NFS.commit)
iseval = 0

[NFSSVRV2(1)]
args = statsmode
definition = $statsmode$(NFS.null),$statsmode$(NFS.getattr),$statsmode$(NFS.setattr),$statsmode$(NFS.root),$statsmode$(NFS.lookup),$statsmode$(NFS.readlink),\
$statsmode$(NFS.read),$statsmode$(NFS.wrcache),$statsmode$(NFS.write),$statsmode$(NFS.create),$statsmode$(NFS.remove),$statsmode$(NFS.rename),$statsmode$(NFS.link),\
$statsmode$(NFS.symlink),$statsmode$(NFS.mkdir),$statsmode$(NFS.rmdir),$statsmode$(NFS.readdir),$statsmode$(NFS.fsstat)
iseval = 0

[NFSCLIV4(1)]
args = statsmode
definition = $statsmode$(NFS.null),$statsmode$(NFS.read),$statsmode$(NFS.write),$statsmode$(NFS.commit),$statsmode$(NFS.open),$statsmode$(NFS.open_conf),$statsmode$(NFS.open_noat),\
$statsmode$(NFS.open_dgrd),$statsmode$(NFS.close),$statsmode$(NFS.setattr),$statsmode$(NFS.fsinfo),$statsmode$(NFS.renew),$statsmode$(NFS.setclntid),\
$statsmode$(NFS.confirm),$statsmode$(NFS.lock),$statsmode$(NFS.lockt),$statsmode$(NFS.locku),$statsmode$(NFS.access),$statsmode$(NFS.getattr),$statsmode$(NFS.lookup),\
$statsmode$(NFS.lookup_root),$statsmode$(NFS.remove),$statsmode$(NFS.rename),$statsmode$(NFS.link),$statsmode$(NFS.symlink),$statsmode$(NFS.create),$statsmode$(NFS.pathconf),\
$statsmode$(NFS.statfs),$statsmode$(NFS.readlink),$statsmode$(NFS.readdir),$statsmode$(NFS.server_caps),$statsmode$(NFS.delegreturn),$statsmode$(NFS.getacl),$statsmode$(NFS.setacl),\
$statsmode$(NFS.fs_locations)
iseval = 0

[NFSCLIV3(1)]
args = statsmode
definition = $statsmode$(NFS.null),$statsmode$(NFS.getattr),$statsmode$(NFS.setattr),$statsmode$(NFS.lookup),$statsmode$(NFS.access),$statsmode$(NFS.readlink),$statsmode$(NFS.read),\
$statsmode$(NFS.write),$statsmode$(NFS.create),$statsmode$(NFS.mkdir),$statsmode$(NFS.symlink),$statsmode$(NFS.mknod),$statsmode$(NFS.remove),$statsmode$(NFS.rmdir),\
$statsmode$(NFS.rename),$statsmode$(NFS.link),$statsmode$(NFS.readdir),$statsmode$(NFS.readdirplus),$statsmode$(NFS.fsstat),$statsmode$(NFS.fsinfo),$statsmode$(NFS.pathconf),\
$statsmode$(NFS.commit)
iseval = 0

[NFSCLIV2(1)]
args = statsmode
definition = $statsmode$(NFS.null),$statsmode$(NFS.getattr),$statsmode$(NFS.setattr),$statsmode$(NFS.root),$statsmode$(NFS.lookup),$statsmode$(NFS.readlink),$statsmode$(NFS.read),\
$statsmode$(NFS.wrcache),$statsmode$(NFS.write),$statsmode$(NFS.create),$statsmode$(NFS.remove),$statsmode$(NFS.rename),$statsmode$(NFS.link),\
$statsmode$(NFS.symlink),$statsmode$(NFS.mkdir),$statsmode$(NFS.rmdir),$statsmode$(NFS.readdir),$statsmode$(NFS.fsstat)
iseval = 0

[VM_Linux(1)]
args = statsmode
definition = $statsmode$(Linux.nr_dirty) As Linux.nr_dirty,\
$statsmode$(Linux.nr_writeback) As Linux.nr_writeback,\
$statsmode$(Linux.nr_unstable) As Linux.nr_unstable,\
$statsmode$(Linux.nr_page_table_pages) As Linux.nr_page_table_pages,\
$statsmode$(Linux.nr_mapped) As Linux.nr_mapped,\
$statsmode$(Linux.nr_slab) As Linux.nr_slab,\
$statsmode$(Linux.pgpgin) As Linux.pgpgin,\
$statsmode$(Linux.pgpgout) As Linux.pgpgout,\
$statsmode$(Linux.pswpin) As Linux.pswpin,\
$statsmode$(Linux.pswpout) As Linux.pswpout,\
$statsmode$(Linux.pgalloc_high) As Linux.pgalloc_high,\
$statsmode$(Linux.pgalloc_normal) As Linux.pgalloc_normal,\
$statsmode$(Linux.pgalloc_dma32) As Linux.pgalloc_dma32,\
$statsmode$(Linux.pgalloc_dma) As Linux.pgalloc_dma,\
$statsmode$(Linux.pgfree) As Linux.pgfree,\
$statsmode$(Linux.pgactivate) As Linux.pgactivate,\
$statsmode$(Linux.pgdeactivate) As Linux.pgdeactivate,\
$statsmode$(Linux.pgfault) As Linux.pgfault,\
$statsmode$(Linux.pgmajfault) As Linux.pgmajfault,\
$statsmode$(Linux.pgrefill_high) As Linux.pgrefill_high,\
$statsmode$(Linux.pgrefill_normal) As Linux.pgrefill_normal,\
$statsmode$(Linux.pgrefill_dma32) As Linux.pgrefill_dma32,\
$statsmode$(Linux.pgrefill_dma) As Linux.pgrefill_dma,\
$statsmode$(Linux.pgsteal_high) As Linux.pgsteal_high,\
$statsmode$(Linux.pgsteal_normal) As Linux.pgsteal_normal,\
$statsmode$(Linux.pgsteal_dma32) As Linux.pgsteal_dma32,\
$statsmode$(Linux.pgsteal_dma) As Linux.pgsteal_dma,\
$statsmode$(Linux.pgscan_kswapd_high) As Linux.pgscan_kswapd_high,\
$statsmode$(Linux.pgscan_kswapd_normal) As Linux.pgscan_kswapd_normal,\
$statsmode$(Linux.pgscan_kswapd_dma32) As Linux.pgscan_kswapd_dma32,\
$statsmode$(Linux.pgscan_kswapd_dma) As Linux.pgscan_kswapd_dma,\
$statsmode$(Linux.pgscan_direct_high) As Linux.pgscan_direct_high,\
$statsmode$(Linux.pgscan_direct_normal) As Linux.pgscan_direct_normal,\
$statsmode$(Linux.pgscan_direct_dma32) As Linux.pgscan_direct_dma32,\
$statsmode$(Linux.pgscan_direct_dma) As Linux.pgscan_direct_dma,\
$statsmode$(Linux.pginodesteal) As Linux.pginodesteal,\
$statsmode$(Linux.slabs_scanned) As Linux.slabs_scanned,\
$statsmode$(Linux.kswapd_steal) As Linux.kswapd_steal,\
$statsmode$(Linux.kswapd_inodesteal) As Linux.kswapd_inodesteal,\
$statsmode$(Linux.pageoutrun) As Linux.pageoutrun,\
$statsmode$(Linux.allocstall) As Linux.allocstall,\
$statsmode$(Linux.pgrotated) As Linux.pgrotated,\
$statsmode$(Linux.nr_bounce) As Linux.nr_bounce
iseval = 0

[VM_Solaris(1)]
args = statsmode
definition = $statsmode$(Solaris.minfaults) As Solaris.minfaults,\
$statsmode$(Solaris.majfaults) As Solaris.majfaults,\
$statsmode$(Solaris.pgin) As Solaris.pgin,\
$statsmode$(Solaris.pgout) As Solaris.pgout,\
$statsmode$(Solaris.scans) As Solaris.scans,\
$statsmode$(Solaris.reclaims) As rSolaris.eclaims,\
$statsmode$(Solaris.pgpgin) As Solaris.pgpgin,\
$statsmode$(Solaris.pgpgout) As Solaris.pgpgout,\
$statsmode$(Solaris.pswpin) As Solaris.pswpin,\
$statsmode$(Solaris.pswpout) As Solaris.pswpout,\
$statsmode$(Solaris.pgfree) As Solaris.pgfree
iseval = 0

####################################################
#																	#
#		macros used in dashboards with tstats			#
#																	#
####################################################

########
# INFO: All these macros must be prefixed by "| tstats" to be used in Splunk views
########

# CPU % usage table stats
[CPU_ALL(5)]
args = statsmode,frameID,OStype,hostname,timefilter
definition = max(CPU.cpu_PCT) AS cpu_PCT from datamodel=NMON_Data_CPU\
where (nodename = CPU.CPU_ALL) (CPU.frameID=$frameID$) (CPU.OStype=$OStype$) (CPU.hostname=$hostname$) `$timefilter$(CPU)` groupby _time, "CPU.frameID", "CPU.hostname" prestats=true\
| stats dedup_splitvals=t max(CPU.cpu_PCT) AS cpu_PCT by _time, "CPU.frameID", "CPU.hostname"\
| stats $statsmode$(cpu_PCT) AS usage by "CPU.frameID", "CPU.hostname" | rename "CPU.frameID" AS frameID "CPU.hostname" AS hostname
iseval = 0

# LPAR VP usage table stats
[LPAR_usage(5)]
args = statsmode,frameID,OStype,hostname,timefilter
definition = max("CPU.lpar_vp_usage") AS lpar_vp_usage, max("CPU.LPAR.lpar_vp_PCT_usage") AS lpar_vp_PCT_usage, max("CPU.entitled") AS entitled, max("CPU.virtualCPUs") AS virtualCPUs\
from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.OStype=$OStype$) (CPU.hostname=$hostname$) (CPU.frameID=$frameID$) `$timefilter$(CPU)` groupby _time,"CPU.frameID","CPU.hostname" prestats=true\
| stats max("CPU.lpar_vp_usage") AS lpar_vp_usage, max("CPU.LPAR.lpar_vp_PCT_usage") AS lpar_vp_PCT_usage, max("CPU.entitled") AS entitled, max("CPU.virtualCPUs") AS virtualCPUs by _time,"CPU.frameID","CPU.hostname"\
| stats $statsmode$("lpar_vp_usage") AS usage, $statsmode$("lpar_vp_PCT_usage") AS usage_PCT, max("entitled") AS entitled, max("virtualCPUs") AS virtualCPUs by "CPU.frameID","CPU.hostname" | rename "CPU.frameID" AS frameID, "CPU.hostname" AS hostname
iseval = 0

# LPAR Pools usage table stats
[LPAR_poolusage(5)]
args = statsmode,frameID,OStype,hostname,timefilter
definition = max("CPU.LPAR.Pool_usage") AS Pool_usage, max("CPU.LPAR.Pool_PCT_usage") AS Pool_PCT_usage, max("CPU.poolCPUs") AS poolCPUs\
from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.PoolIdle>0) (CPU.LPAR.Pool_id=0) (CPU.OStype=$OStype$) (CPU.hostname=$hostname$) (CPU.frameID=$frameID$) `$timefilter$(CPU)` groupby _time,"CPU.frameID","CPU.hostname" prestats=true\
| stats max("CPU.LPAR.Pool_usage") AS Pool_usage, max("CPU.LPAR.Pool_PCT_usage") AS Pool_PCT_usage, max("CPU.poolCPUs") AS poolCPUs by _time,"CPU.frameID","CPU.hostname"\
| search (Pool_usage!=poolCPUs)\
| stats $statsmode$("Pool_usage") AS usage, $statsmode$("Pool_PCT_usage") AS usage_PCT, max("poolCPUs") AS poolCPUs by "CPU.frameID","CPU.hostname" | rename "CPU.frameID" AS frameID, "CPU.hostname" AS hostname\
| sort - usage | dedup frameID
iseval = 0

# Memory usage table stats
[MEM(5)]
args = statsmode,frameID,OStype,hostname,timefilter
definition = max("MEM.allOS_Real_Free_PCT") AS allOS_Real_Free_PCT max("MEM.allOS_Real_total_MB") AS allOS_Real_total_MB max("MEM.allOS_Real_used_MB") AS allOS_Real_used_MB\
max("MEM.allOS_Real_used_PCT") AS allOS_Real_used_PCT max("MEM.allOS_Virtual_free_PCT") AS allOS_Virtual_free_PCT max("MEM.allOS_Virtual_total_MB") AS allOS_Virtual_total_MB\
max("MEM.allOS_Virtual_used_MB") AS allOS_Virtual_used_MB max("MEM.allOS_Virtual_used_PCT") AS allOS_Virtual_used_PCT from datamodel=NMON_Data_MEM\
where (nodename = MEM) (MEM.OStype=$OStype$) (MEM.hostname=$hostname$) (MEM.frameID=$frameID$)\
groupby _time, "MEM.frameID", "MEM.hostname" prestats=true\
| stats dedup_splitvals=t max("MEM.allOS_Real_Free_PCT") AS allOS_Real_Free_PCT max("MEM.allOS_Real_total_MB") AS allOS_Real_total_MB max("MEM.allOS_Real_used_MB") AS allOS_Real_used_MB\
max("MEM.allOS_Real_used_PCT") AS allOS_Real_used_PCT max("MEM.allOS_Virtual_free_PCT") AS allOS_Virtual_free_PCT max("MEM.allOS_Virtual_total_MB") AS allOS_Virtual_total_MB\
max("MEM.allOS_Virtual_used_MB") AS allOS_Virtual_used_MB max("MEM.allOS_Virtual_used_PCT") AS allOS_Virtual_used_PCT by _time, "MEM.frameID", "MEM.hostname"\
| stats dedup_splitvals=t $statsmode$("allOS_Real_Free_PCT") AS Real_Free_PCT $statsmode$("allOS_Real_total_MB") AS Real_total_MB $statsmode$("allOS_Real_used_MB") AS Real_used_MB\
$statsmode$("allOS_Real_used_PCT") AS Real_used_PCT $statsmode$("allOS_Virtual_free_PCT") AS Virtual_free_PCT $statsmode$("allOS_Virtual_total_MB") AS Virtual_total_MB\
$statsmode$("allOS_Virtual_used_MB") AS Virtual_used_MB $statsmode$("allOS_Virtual_used_PCT") AS Virtual_used_PCT by "MEM.frameID", "MEM.hostname"\
| rename "MEM.frameID" AS "frameID" "MEM.hostname" AS hostname
iseval = 0


####
# d3chart django dashboard, Processes usage (TOP)
###

# TOP Processes cpu usage table stats

[TOP_AIX_cpu(6)]
args = frameID,OStype,hostname,timefilter,Command,PID
definition = max("TOP_AIX.pct_CPU") AS pct_CPU from datamodel=NMON_Data_TOP\
where (nodename = TOP_AIX) (TOP_AIX.OStype=$OStype$) (TOP_AIX.frameID=$frameID$) (TOP_AIX.hostname=$hostname$) `$timefilter$(TOP_AIX)` (TOP_AIX.Command=$Command$) (TOP_AIX.PID=$PID$)\
groupby _time, "TOP_AIX.hostname", "TOP_AIX.logical_cpus", "TOP_AIX.Command", "TOP_AIX.PID" prestats=true span=1m\
| bucket _time span=1m\
| stats dedup_splitvals=t max("TOP_AIX.pct_CPU") AS pct_CPU by _time, "TOP_AIX.hostname", "TOP_AIX.logical_cpus", "TOP_AIX.Command", "TOP_AIX.PID"\
| rename "TOP_AIX.hostname" AS hostname "TOP_AIX.logical_cpus" AS logical_cpus "TOP_AIX.Command" AS Command "TOP_AIX.PID" AS PID | eval limit=(logical_cpus*100) | where (pct_CPU<=limit)
iseval = 0

[TOP_Linux_cpu(6)]
args = frameID,OStype,hostname,timefilter,Command,PID
definition = max("TOP_Linux.pct_CPU") AS pct_CPU from datamodel=NMON_Data_TOP.TOP_Linux\
where (nodename = TOP_Linux) (TOP_Linux.OStype=$OStype$) (TOP_Linux.frameID=$frameID$) (TOP_Linux.hostname=$hostname$) `$timefilter$(TOP_Linux)` (TOP_Linux.Command=$Command$) (TOP_Linux.PID=$PID$)\
groupby _time, "TOP_Linux.hostname", "TOP_Linux.logical_cpus", "TOP_Linux.Command", "TOP_Linux.PID" prestats=true span=1m\
| bucket _time span=1m\
| stats dedup_splitvals=t max("TOP_Linux.pct_CPU") AS pct_CPU by _time, "TOP_Linux.hostname", "TOP_Linux.logical_cpus", "TOP_Linux.Command", "TOP_Linux.PID"\
| rename "TOP_Linux.hostname" AS hostname "TOP_Linux.logical_cpus" AS logical_cpus "TOP_Linux.Command" AS Command "TOP_Linux.PID" AS PID | eval limit=(logical_cpus*100) | where (pct_CPU<=limit)
iseval = 0

[TOP_Solaris_cpu(6)]
args = frameID,OStype,hostname,timefilter,Command,PID 
definition = max("TOP_Solaris.pct_CPU") AS pct_CPU from datamodel=NMON_Data_TOP.TOP_Solaris\
where (nodename = TOP_Solaris) (TOP_Solaris.OStype=$OStype$) (TOP_Solaris.frameID=$frameID$) (TOP_Solaris.hostname=$hostname$) `$timefilter$(TOP_Solaris)` (TOP_Solaris.Command=$Command$) (TOP_Solaris.PID=$PID$)\
groupby _time, "TOP_Solaris.hostname", "TOP_Solaris.logical_cpus", "TOP_Solaris.Command", "TOP_Solaris.PID" prestats=true span=1m\
| bucket _time span=1m\
| stats dedup_splitvals=t max("TOP_Solaris.pct_CPU") AS pct_CPU by _time, "TOP_Solaris.hostname", "TOP_Solaris.logical_cpus", "TOP_Solaris.Command", "TOP_Solaris.PID"\
| rename "TOP_Solaris.hostname" AS hostname "TOP_Solaris.logical_cpus" AS logical_cpus "TOP_Solaris.Command" AS Command "TOP_Solaris.PID" AS PID | eval limit=(logical_cpus*100) | where (pct_CPU<=limit)
iseval = 0


# TOP AIX Processes memory usage table stats

[TOP_AIX_mem(6)]
args = frameID,OStype,hostname,timefilter,Command,PID
definition = max("TOP_AIX.ResText") AS ResText max("TOP_AIX.ResData") AS ResData from datamodel=NMON_Data_TOP\
where (nodename = TOP_AIX) (TOP_AIX.OStype=$OStype$) (TOP_AIX.frameID=$frameID$) (TOP_AIX.hostname=$hostname$) `$timefilter$(TOP_AIX)` (TOP_AIX.Command=$Command$) (TOP_AIX.PID=$PID$)\
groupby _time, "TOP_AIX.hostname", "TOP_AIX.logical_cpus", "TOP_AIX.Command", "TOP_AIX.PID" prestats=true span=1m\
| bucket _time span=1m\
| stats dedup_splitvals=t max("TOP_AIX.ResText") AS ResText max("TOP_AIX.ResData") AS ResData by _time, "TOP_AIX.hostname", "TOP_AIX.logical_cpus", "TOP_AIX.Command", "TOP_AIX.PID"\
| rename "TOP_AIX.hostname" AS hostname "TOP_AIX.logical_cpus" AS logical_cpus "TOP_AIX.Command" AS Command "TOP_AIX.PID" AS PID\
| eval Used_Mem_MB=((ResData+ResText)/1024)
iseval = 0

[TOP_Linux_mem(6)]
args = frameID,OStype,hostname,timefilter,Command,PID
definition = max("TOP_Linux.ResText") AS ResText max("TOP_Linux.ResData") AS ResData from datamodel=NMON_Data_TOP.TOP_Linux\
where (nodename = TOP_Linux) (TOP_Linux.OStype=$OStype$) (TOP_Linux.frameID=$frameID$) (TOP_Linux.hostname=$hostname$) `$timefilter$(TOP_Linux)` (TOP_Linux.Command=$Command$) (TOP_Linux.PID=$PID$)\
groupby _time, "TOP_Linux.hostname", "TOP_Linux.logical_cpus", "TOP_Linux.Command", "TOP_Linux.PID" prestats=true span=1m\
| bucket _time span=1m\
| stats dedup_splitvals=t max("TOP_Linux.ResText") AS ResText max("TOP_Linux.ResData") AS ResData by _time, "TOP_Linux.hostname", "TOP_Linux.logical_cpus", "TOP_Linux.Command", "TOP_Linux.PID"\
| rename "TOP_Linux.hostname" AS hostname "TOP_Linux.logical_cpus" AS logical_cpus "TOP_Linux.Command" AS Command "TOP_Linux.PID" AS PID | eval Used_Mem_MB=((ResData+ResText)/1024)
iseval = 0

[TOP_Solaris_mem(6)]
args = frameID,OStype,hostname,timefilter,Command,PID
definition = max("TOP_Solaris.ResSize") AS ResSize from datamodel=NMON_Data_TOP.TOP_Solaris\
where (nodename = TOP_Solaris) (TOP_Solaris.OStype=$OStype$) (TOP_Solaris.frameID=$frameID$) (TOP_Solaris.hostname=$hostname$) `$timefilter$(TOP_Solaris)` (TOP_Solaris.Command=$Command$) (TOP_Solaris.PID=$PID$)\
groupby _time, "TOP_Solaris.hostname", "TOP_Solaris.logical_cpus", "TOP_Solaris.Command", "TOP_Solaris.PID" prestats=true span=1m\
| bucket _time span=1m\
| stats dedup_splitvals=t max("TOP_Solaris.ResSize") AS ResSize by _time, "TOP_Solaris.hostname", "TOP_Solaris.logical_cpus", "TOP_Solaris.Command", "TOP_Solaris.PID"\
| eval Used_Mem_MB=round(((ResSize)/1024),2)\
| rename "TOP_Solaris.hostname" AS hostname "TOP_Solaris.logical_cpus" AS logical_cpus "TOP_Solaris.Command" AS Command "TOP_Solaris.PID" AS PID
iseval = 0

#
# Heat Map Calendar by Performance Monitor

[frameID_populate(2)]
args = datamodel,node
definition = $datamodel$ $node$ count($node$) AS "count" SPLITROW frameID AS frameID SORT 0 frameID ROWSUMMARY 0 COLSUMMARY 0 NUMCOLS 0 SHOWOTHER 1
iseval = 0

[heatmap_calendar_dcount(4)]
args = datamodel,node,frameID,hostname
definition = $datamodel$ $node$ dc(hostname) AS dcount SPLITROW _time AS _time PERIOD day FILTER frameID is $frameID$ FILTER hostname is $hostname$ SORT 0 _time ROWSUMMARY 0 COLSUMMARY 0 NUMCOLS 0 SHOWOTHER 1 | where dcount>0 | rename dcount AS "Distinct count of hosts per day"
iseval = 0

[heatmap_calendar_count(4)]
args = datamodel,node,frameID,hostname
definition = $datamodel$ $node$ count($node$) AS count SPLITROW _time AS _time PERIOD day FILTER frameID is $frameID$ FILTER hostname is $hostname$ SORT 0 _time ROWSUMMARY 0 COLSUMMARY 0 NUMCOLS 0 SHOWOTHER 1 | where count>0 | rename count AS "Count of events per day"
iseval = 0


#
# Solaris WLM Macros

[WLM_Solaris_statistics(8)]
args = monitor,report,frameID,hostname,statsmode,timefilter,device,device_name
definition = tstats max("WLM.$report$") AS value, max(WLM.logical_cpus) As logical_cpus from datamodel=NMON_Data_WLM\
where (nodename = WLM.$monitor$) (WLM.hostname=$hostname$) (WLM.frameID=$frameID$) (WLM.hostname=$hostname$) (WLM.device=$device$) `$timefilter$(WLM)`\
groupby _time, "WLM.hostname", "WLM.device" prestats=true span=1m\
| stats dedup_splitvals=t max("WLM.$report$") AS value, max(WLM.logical_cpus) As logical_cpus by _time, "WLM.hostname", "WLM.device"\
| rename "WLM.hostname" AS hostname, "WLM.device" AS device\
| stats max(value) AS max_value, avg(value) AS avg_value, min(value) AS min_value by "device"\
| fields device,max_value, avg_value, min_value\
| rename device AS $device_name$\
| foreach "*_value" [ eval "<<FIELD>>"=round('<<FIELD>>', 2) ] | sort - avg_value
iseval = 0

[WLM_Solaris_statistics_byhost(8)]
args = monitor,report,frameID,hostname,statsmode,timefilter,device,device_name
definition = tstats max("WLM.$report$") AS value, max(WLM.logical_cpus) As logical_cpus from datamodel=NMON_Data_WLM\
where (nodename = WLM.$monitor$) (WLM.hostname=$hostname$) (WLM.frameID=$frameID$) (WLM.hostname=$hostname$) (WLM.device=$device$) `$timefilter$(WLM)`\
groupby _time, "WLM.hostname", "WLM.device" prestats=true span=1m\
| stats dedup_splitvals=t max("WLM.$report$") AS value, max(WLM.logical_cpus) As logical_cpus by _time, "WLM.hostname", "WLM.device"\
| rename "WLM.hostname" AS hostname, "WLM.device" AS device\
| stats max(logical_cpus) As logical_cpus, max(value) AS max_value, avg(value) AS avg_value, min(value) AS min_value by "hostname", "device"\
| sort limit=0 "hostname"\
| fields hostname,logical_cpus,device,max_value, avg_value, min_value\
| rename device AS $device_name$, logical_cpus AS "host logical cpus"\
| foreach "*_value" [ eval "<<FIELD>>"=round('<<FIELD>>', 2) ] | sort - avg_value
iseval = 0


###################
# ALERTING MACROS #
###################

[alerting_cpu_usage(5)]
args = frameID,hostname,alert_usage,min_duration,max_pause
definition = eventtype="nmon:performance:cpu" type=CPU_ALL OR type=LPAR frameID="$frameID$" hostname="$hostname$"\
| eval CPU_ALL_cpu_PCT=round((Sys_PCT+User_PCT+Wait_PCT),2)\
| eval LPAR_cpu_PCT=round((VP_User_PCT+VP_Sys_PCT+VP_Wait_PCT+VP_Idle_PCT),2)\
| eval cpu_PCT=if(isnull(LPAR_cpu_PCT), CPU_ALL_cpu_PCT, LPAR_cpu_PCT)\
| eval Sys_PCT=if(isnull(VP_Sys_PCT), Sys_PCT, VP_Sys_PCT)\
| where cpu_PCT>$alert_usage$\
| eval datasource=if(isnull(LPAR_cpu_PCT), "CPU_ALL", "LPAR")\
| foreach Sys_PCT User_PCT Wait_PCT Idle_PCT [ eval <<FIELD>>=if(isnull(VP_<<FIELD>>), <<FIELD>>, VP_<<FIELD>>) ]\
| transaction frameID hostname cpu_PCT maxpause=$max_pause$ | where duration>$min_duration$\
| fields _time,frameID,hostname,datasource,duration,cpu_PCT,Sys_PCT,User_PCT,Wait_PCT,Idle_PCT | stats values(*) AS * by _time,frameID,hostname\
| eval "duration (hh:mm:ss)"=tostring(duration,"duration") | rename duration AS "duration (seconds)"\
| fields _time,frameID,hostname,datasource,duration*,cpu_PCT,Sys_PCT,User_PCT,Wait_PCT,Idle_PCT
iseval = 0

[alerting_PSERIES_pools_cpu_usage(6)]
args = frameID,Pool_id,hostname,alert_usage,min_duration,max_pause
definition = eventtype="nmon:performance:cpu" type=LPAR frameID="$frameID$" hostname="$hostname$" Pool_id="$Pool_id$" PoolIdle>0\
| eval Pool_PCT_usage=round(((poolCPUs-PoolIdle)*100/poolCPUs),2)\
| eval Pool_VP_usage=round((poolCPUs-PoolIdle),2)\
| where Pool_PCT_usage>$alert_usage$\
| transaction frameID Pool_id Pool_PCT_usage maxpause=$max_pause$ | where duration>$min_duration$\
| fields _time,frameID,Pool_id,duration,Pool_PCT_usage,Pool_VP_usage,poolCPUs\
| stats values(*) AS * by _time,frameID,Pool_id\
| eval "duration (hh:mm:ss)"=tostring(duration,"duration") | rename duration AS "duration (seconds)"\
| fields _time,frameID,Pool_id,duration*,Pool_PCT_usage,Pool_VP_usage,poolCPUs
iseval = 0

[alerting_filesystem_usage(5)]
args = frameID,hostname,alert_usage,min_duration,max_pause
definition = eventtype="nmon:performance:storage" type=JFSFILE type=JFSFILE frameID="$frameID$" hostname="$hostname$" value>$alert_usage$\
| lookup filesystem_excluding device OUTPUTNEW exclude | where isnull(exclude)\
| transaction frameID hostname device value maxpause=$max_pause$ | where duration>$min_duration$\
| stats max(value) AS "% usage" by _time,frameID,hostname,device
iseval = 0

[alerting_realmemory_usage(5)]
args = frameID,hostname,alert_usage,min_duration,max_pause
definition = eventtype="nmon:performance:memory" type=MEM frameID="$frameID$" hostname="$hostname$"\
| eval real_memory_usage_PCT=if(isnotnull(mem_used_effective_PCT), mem_used_effective_PCT, mem_used_PCT)\
| eval real_memory_used_MB=if(isnotnull(mem_used_effective), mem_used_effective, mem_used)\
| eval real_memory_free_MB=if(isnotnull(mem_free_effective), mem_free_effective, mem_free)\
| rename mem AS real_memory_total_MB\
| where real_memory_usage_PCT>$alert_usage$\
| transaction frameID hostname real_memory_usage_PCT maxpause=$max_pause$ | where duration>$min_duration$\
| fields _time,frameID,hostname,real_memory_usage_PCT,real_memory_total_MB,real_memory_used_MB,real_memory_free_MB,buffers,cached,duration\
| stats values(*) AS * by _time,frameID,hostname\
| eval "duration (hh:mm:ss)"=tostring(duration,"duration") | rename duration AS "duration (seconds)"\
| rename *_PCT AS "* (%)", *_MB AS "* (MB)"\
| fields _time,frameID,hostname,duration*,"*(%)",*
iseval = 0

[alerting_virtualmemory_usage(5)]
args = frameID,hostname,alert_usage,min_duration,max_pause
definition = eventtype="nmon:performance:memory" type=MEM frameID="$frameID$" hostname="$hostname$"\
| eval virtual_memory_usage_PCT=if(isnotnull(swap_used_effective_PCT), swap_used_effective_PCT, swap_used_PCT)\
| eval virtual_memory_used_MB=if(isnotnull(swap_used_effective), swap_used_effective, swap_used)\
| eval virtual_memory_free_MB=if(isnotnull(swap_free_effective), swap_free_effective, swap_free)\
| rename swap AS virtual_memory_total_MB\
| where virtual_memory_usage_PCT>$alert_usage$\
| transaction frameID hostname virtual_memory_usage_PCT maxpause=$max_pause$ | where duration>$min_duration$\
| fields _time,frameID,hostname,virtual_memory_usage_PCT,virtual_memory_total_MB,virtual_memory_used_MB,virtual_memory_free_MB,swapcached,duration\
| stats values(*) AS * by _time,frameID,hostname\
| eval "duration (hh:mm:ss)"=tostring(duration,"duration") | rename duration AS "duration (seconds)"\
| rename *_PCT AS "* (%)", *_MB AS "* (MB)"\
| fields _time,frameID,hostname,duration*,"*(%)",*
iseval = 0


###################
# BASELINE MACROS #
###################

### Baseline generation macros ###

#
# CPU_ALL
# Average CPU usage, relevant for ALL OS
#

# CPU usage with simple baseline able to chart in the future - future charting capable
[nmon_cpu_pct_simple_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("CPU.cpu_PCT") AS cpu_PCT from datamodel=NMON_Data_CPU where (nodename = CPU.CPU_ALL) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.cpu_PCT") AS cpu_PCT by _time, "CPU.hostname"\
| rename CPU.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_CPU_ALL date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(cpu_PCT) AS cpu_PCT, avg(baseline_avg_cpu) AS baseline_avg_cpu
iseval = 0

# CPU usage with simple baseline able to chart in the future - no future charting
[nmon_cpu_pct_simple_baseline(2)]
args= hostname,statsmode
definition = tstats avg("CPU.cpu_PCT") AS cpu_PCT from datamodel=NMON_Data_CPU where (nodename = CPU.CPU_ALL) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.cpu_PCT") AS cpu_PCT by _time, "CPU.hostname"\
| rename CPU.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_CPU_ALL date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(cpu_PCT) AS cpu_PCT, avg(baseline_avg_cpu) AS baseline_avg_cpu
iseval = 0

# CPU usage with lower, average and upper baseline (predict command rendering) - future charting capable
[nmon_cpu_pct_full_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("CPU.cpu_PCT") AS cpu_PCT from datamodel=NMON_Data_CPU where (nodename = CPU.CPU_ALL) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.cpu_PCT") AS cpu_PCT by _time, "CPU.hostname"\
| rename CPU.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_CPU_ALL date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(cpu_PCT) AS cpu_PCT, avg(lower_baseline_avg_cpu) AS lower, avg(baseline_avg_cpu) AS predicted, avg(upper_baseline_avg_cpu) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

# CPU usage with lower, average and upper baseline (predict command rendering) - no future charting
[nmon_cpu_pct_full_baseline(2)]
args= hostname,statsmode
definition = tstats avg("CPU.cpu_PCT") AS cpu_PCT from datamodel=NMON_Data_CPU where (nodename = CPU.CPU_ALL) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.cpu_PCT") AS cpu_PCT by _time, "CPU.hostname"\
| rename CPU.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_CPU_ALL date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(cpu_PCT) AS cpu_PCT, avg(lower_baseline_avg_cpu) AS lower, avg(baseline_avg_cpu) AS predicted, avg(upper_baseline_avg_cpu) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

#
# LPAR
# Average AIX micro-partitions Virtual CPU usage, relevant for AIX OS only
#

# Virtual CPU usage with simple baseline - future charting capable
[nmon_vp_usage_simple_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("CPU.lpar_vp_usage") AS vp_usage max("CPU.entitled") AS entitled max("CPU.virtualCPUs") AS virtualCPUs\
from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.lpar_vp_usage") AS vp_usage max("CPU.entitled") AS entitled max("CPU.virtualCPUs") AS virtualCPUs by _time, "CPU.hostname"\
| rename CPU.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_LPAR date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(vp_usage) AS vp_usage, max(entitled) AS entitled, max(virtualCPUs) AS virtualCPUs, avg(baseline_avg_vp_usage) AS baseline_avg_vp_usage
iseval = 0

# Virtual CPU usage with simple baseline - no future charting
[nmon_vp_usage_simple_baseline(2)]
args= hostname,statsmode
definition = tstats avg("CPU.lpar_vp_usage") AS vp_usage max("CPU.entitled") AS entitled max("CPU.virtualCPUs") AS virtualCPUs\
from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.lpar_vp_usage") AS vp_usage max("CPU.entitled") AS entitled max("CPU.virtualCPUs") AS virtualCPUs by _time, "CPU.hostname"\
| rename CPU.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_LPAR date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(vp_usage) AS vp_usage, max(entitled) AS entitled, max(virtualCPUs) AS virtualCPUs, avg(baseline_avg_vp_usage) AS baseline_avg_vp_usage
iseval = 0

# Virtual CPU usage with lower, average and upper baseline (predict command rendering) - future charting capable
[nmon_vp_usage_full_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("CPU.lpar_vp_usage") AS vp_usage max("CPU.entitled") AS entitled max("CPU.virtualCPUs") AS virtualCPUs\
from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.lpar_vp_usage") AS vp_usage max("CPU.entitled") AS entitled max("CPU.virtualCPUs") AS virtualCPUs\
by _time, "CPU.hostname"\
| rename CPU.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_LPAR date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(vp_usage) AS vp_usage, max(entitled) AS entitled, max(virtualCPUs) AS virtualCPUs\
avg(lower_baseline_avg_vp_usage) AS lower, avg(baseline_avg_vp_usage) AS predicted, avg(upper_baseline_avg_vp_usage) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

# Virtual CPU usage with lower, average and upper baseline (predict command rendering) - no future charting
[nmon_vp_usage_full_baseline(2)]
args= hostname,statsmode
definition = tstats avg("CPU.lpar_vp_usage") AS vp_usage max("CPU.entitled") AS entitled max("CPU.virtualCPUs") AS virtualCPUs\
from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.lpar_vp_usage") AS vp_usage max("CPU.entitled") AS entitled max("CPU.virtualCPUs") AS virtualCPUs\
by _time, "CPU.hostname"\
| rename CPU.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_LPAR date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(vp_usage) AS vp_usage, max(entitled) AS entitled, max(virtualCPUs) AS virtualCPUs\
avg(lower_baseline_avg_vp_usage) AS lower, avg(baseline_avg_vp_usage) AS predicted, avg(upper_baseline_avg_vp_usage) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

# Pool Virtual CPU usage with simple baseline - future charting capable
[nmon_pool_usage_simple_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("CPU.LPAR.Pool_usage") AS pool_usage max("CPU.poolCPUs") AS poolCPUs from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.LPAR.Pool_usage") AS pool_usage max("CPU.poolCPUs") AS poolCPUs by _time, "CPU.hostname"\
| rename CPU.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_LPAR date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(pool_usage) AS pool_usage, max(poolCPUs) AS poolCPUs, avg(baseline_avg_pool_usage) AS baseline_avg_pool_usage
iseval = 0

# Pool Virtual CPU usage with simple baseline - no future charting
[nmon_pool_usage_simple_baseline(2)]
args= hostname,statsmode
definition = tstats avg("CPU.LPAR.Pool_usage") AS pool_usage max("CPU.poolCPUs") AS poolCPUs from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.LPAR.Pool_usage") AS pool_usage max("CPU.poolCPUs") AS poolCPUs by _time, "CPU.hostname"\
| rename CPU.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_LPAR date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(pool_usage) AS pool_usage, max(poolCPUs) AS poolCPUs, avg(baseline_avg_pool_usage) AS baseline_avg_pool_usage
iseval = 0

# Pool CPU usage with lower, average and upper baseline (predict command rendering) - future charting capable
[nmon_pool_usage_full_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("CPU.LPAR.Pool_usage") AS pool_usage max("CPU.poolCPUs") AS poolCPUs from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.LPAR.Pool_usage") AS pool_usage max("CPU.poolCPUs") AS poolCPUs by _time, "CPU.hostname"\
| rename CPU.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_LPAR date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(pool_usage) AS pool_usage, max(poolCPUs) AS poolCPUs, avg(lower_baseline_avg_pool_usage) AS lower, avg(baseline_avg_pool_usage) AS predicted, avg(upper_baseline_avg_pool_usage) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

# Pool CPU usage with lower, average and upper baseline (predict command rendering) - no future charting
[nmon_pool_usage_full_baseline(2)]
args= hostname,statsmode
definition = tstats avg("CPU.LPAR.Pool_usage") AS pool_usage max("CPU.poolCPUs") AS poolCPUs from datamodel=NMON_Data_CPU where (nodename = CPU.LPAR) (CPU.hostname=$hostname$)\
groupby _time, "CPU.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("CPU.LPAR.Pool_usage") AS pool_usage max("CPU.poolCPUs") AS poolCPUs by _time, "CPU.hostname"\
| rename CPU.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_LPAR date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(pool_usage) AS pool_usage, max(poolCPUs) AS poolCPUs, avg(lower_baseline_avg_pool_usage) AS lower, avg(baseline_avg_pool_usage) AS predicted, avg(upper_baseline_avg_pool_usage) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

#
# MEM
# Average Real and Virtual Memory usage, relevant for ALL OS
#

# Real Memory Usage (in percentage) with simple baseline - future charting capabable
[nmon_real_mem_simple_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("MEM.mem_used_effective_PCT") AS avg_real_mem from datamodel=NMON_Data_MEM where (nodename = MEM) (MEM.hostname=$hostname$)\
groupby _time, "MEM.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("MEM.mem_used_effective_PCT") AS avg_real_mem by _time, "MEM.hostname"\
| rename MEM.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_MEM date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(avg_real_mem) AS avg_real_mem, avg(baseline_avg_real_mem) AS baseline_avg_real_mem
iseval = 0

# Real Memory Usage (in percentage) with simple baseline - no future charting
[nmon_real_mem_simple_baseline(2)]
args= hostname,statsmode
definition = tstats avg("MEM.mem_used_effective_PCT") AS avg_real_mem from datamodel=NMON_Data_MEM where (nodename = MEM) (MEM.hostname=$hostname$)\
groupby _time, "MEM.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("MEM.mem_used_effective_PCT") AS avg_real_mem by _time, "MEM.hostname"\
| rename MEM.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_MEM date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(avg_real_mem) AS avg_real_mem, avg(baseline_avg_real_mem) AS baseline_avg_real_mem
iseval = 0

# Real Memory Usage (in percentage) with lower, average and upper baseline (predict command rendering) - future charting capable
[nmon_real_mem_full_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("MEM.mem_used_effective_PCT") AS avg_real_mem from datamodel=NMON_Data_MEM where (nodename = MEM) (MEM.hostname=$hostname$)\
groupby _time, "MEM.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("MEM.mem_used_effective_PCT") AS avg_real_mem by _time, "MEM.hostname"\
| rename MEM.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_MEM date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(avg_real_mem) AS avg_real_mem, avg(lower_baseline_avg_real_mem) AS lower, avg(baseline_avg_real_mem) AS predicted, avg(upper_baseline_avg_real_mem) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

# Real Memory Usage (in percentage) with lower, average and upper baseline (predict command rendering) - no future charting
[nmon_real_mem_full_baseline(2)]
args= hostname,statsmode
definition = tstats avg("MEM.mem_used_effective_PCT") AS avg_real_mem from datamodel=NMON_Data_MEM where (nodename = MEM) (MEM.hostname=$hostname$)\
groupby _time, "MEM.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("MEM.mem_used_effective_PCT") AS avg_real_mem by _time, "MEM.hostname"\
| rename MEM.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_MEM date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(avg_real_mem) AS avg_real_mem, avg(lower_baseline_avg_real_mem) AS lower, avg(baseline_avg_real_mem) AS predicted, avg(upper_baseline_avg_real_mem) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

# Virtual Memory Usage (in percentage) with simple baseline - future charting capable
[nmon_virtual_mem_simple_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("MEM.swap_used_effective_PCT") AS avg_virtual_mem from datamodel=NMON_Data_MEM where (nodename = MEM) (MEM.hostname=$hostname$)\
groupby _time, "MEM.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("MEM.swap_used_effective_PCT") AS avg_virtual_mem by _time, "MEM.hostname"\
| rename MEM.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_MEM date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(avg_virtual_mem) AS avg_virtual_mem, avg(baseline_avg_virtual_mem) AS baseline_avg_virtual_mem
iseval = 0

# Virtual Memory Usage (in percentage) with simple baseline - no future charting
[nmon_virtual_mem_simple_baseline(2)]
args= hostname,statsmode
definition = tstats avg("MEM.swap_used_effective_PCT") AS avg_virtual_mem from datamodel=NMON_Data_MEM where (nodename = MEM) (MEM.hostname=$hostname$)\
groupby _time, "MEM.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("MEM.swap_used_effective_PCT") AS avg_virtual_mem by _time, "MEM.hostname"\
| rename MEM.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_MEM date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(avg_virtual_mem) AS avg_virtual_mem, avg(baseline_avg_virtual_mem) AS baseline_avg_virtual_mem
iseval = 0

# Virtual Memory Usage (in percentage) with lower, average and upper baseline (predict command rendering) - future charting capable
[nmon_virtual_mem_full_baseline_future(2)]
args= hostname,statsmode
definition = tstats avg("MEM.swap_used_effective_PCT") AS avg_virtual_mem from datamodel=NMON_Data_MEM where (nodename = MEM) (MEM.hostname=$hostname$)\
groupby _time, "MEM.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("MEM.swap_used_effective_PCT") AS avg_virtual_mem by _time, "MEM.hostname"\
| rename MEM.* AS *\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_MEM date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(avg_virtual_mem) AS avg_virtual_mem, avg(lower_baseline_avg_virtual_mem) AS lower, avg(baseline_avg_virtual_mem) AS predicted, avg(upper_baseline_avg_virtual_mem) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

# Virtual Memory Usage (in percentage) with lower, average and upper baseline (predict command rendering) - no future charting
[nmon_virtual_mem_full_baseline(2)]
args= hostname,statsmode
definition = tstats avg("MEM.swap_used_effective_PCT") AS avg_virtual_mem from datamodel=NMON_Data_MEM where (nodename = MEM) (MEM.hostname=$hostname$)\
groupby _time, "MEM.hostname" prestats=true span=5m\
| stats dedup_splitvals=t avg("MEM.swap_used_effective_PCT") AS avg_virtual_mem by _time, "MEM.hostname"\
| rename MEM.* AS *\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_MEM date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(avg_virtual_mem) AS avg_virtual_mem, avg(lower_baseline_avg_virtual_mem) AS lower, avg(baseline_avg_virtual_mem) AS predicted, avg(upper_baseline_avg_virtual_mem) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

#
# DISKXFER
# Average Number of disk I/O per sec stats, relevant for ALL OS
#

# Average IOPS with simple baseline - future charting capable
[nmon_iops_simple_baseline_future(2)]
args= hostname,statsmode
definition = tstats sum("DISKXFER.value") AS "DISKXFER.value" from datamodel=NMON_Data_DISKXFER where (nodename = DISKXFER) (DISKXFER.hostname=$hostname$)\
groupby _time, "DISKXFER.hostname", "DISKXFER.date_wday", "DISKXFER.local_time" prestats=true span=1m\
| bucket _time span=1m | stats dedup_splitvals=t sum("DISKXFER.value") AS "DISKXFER.value" by _time, "DISKXFER.hostname", "DISKXFER.date_wday", "DISKXFER.local_time"\
| rename DISKXFER.* AS *\
| bucket _time span=5m | stats avg(value) AS value by _time, hostname\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_DISKXFER date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(value) AS disk_iops, avg(baseline_avg_disk_iops) AS baseline_disk_iops
iseval = 0

# Average IOPS with simple baseline - no future charting
[nmon_iops_simple_baseline(2)]
args= hostname,statsmode
definition = tstats sum("DISKXFER.value") AS "DISKXFER.value" from datamodel=NMON_Data_DISKXFER where (nodename = DISKXFER) (DISKXFER.hostname=$hostname$)\
groupby _time, "DISKXFER.hostname" prestats=true span=1m\
| bucket _time span=1m | stats dedup_splitvals=t sum("DISKXFER.value") AS "DISKXFER.value" by _time, "DISKXFER.hostname"\
| rename DISKXFER.* AS *\
| bucket _time span=5m | stats avg(value) AS value by _time, hostname\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_DISKXFER date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(value) AS disk_iops, avg(baseline_avg_disk_iops) AS baseline_disk_iops
iseval = 0

# Average IOPS with lower, average and upper baseline (predict command rendering) - future charting capable
[nmon_iops_full_baseline_future(2)]
args= hostname,statsmode
definition = tstats sum("DISKXFER.value") AS "DISKXFER.value" from datamodel=NMON_Data_DISKXFER where (nodename = DISKXFER) (DISKXFER.hostname=$hostname$)\
groupby _time, "DISKXFER.hostname", "DISKXFER.date_wday", "DISKXFER.local_time" prestats=true span=1m\
| bucket _time span=1m | stats dedup_splitvals=t sum("DISKXFER.value") AS "DISKXFER.value" by _time, "DISKXFER.hostname", "DISKXFER.date_wday", "DISKXFER.local_time"\
| rename DISKXFER.* AS *\
| bucket _time span=5m | stats avg(value) AS value by _time, hostname\
| append [ | gentimes start=[| stats count | addinfo | eval start=strftime('info_min_time', "%m/%d/%Y:%H:%M:%S") | return start] end=[| stats count | addinfo | eval end=strftime('info_max_time', "%m/%d/%Y:%H:%M:%S")\
| return end] increment=5m | eval _time=starttime | eval hostname="$hostname$"\
| timechart span=5m count by hostname | untable _time hostname count | fields - count ]\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_DISKXFER date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(value) AS disk_iops,\
avg(lower_baseline_avg_disk_iops) AS lower, avg(baseline_avg_disk_iops) AS predicted, avg(upper_baseline_avg_disk_iops) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0

# Average IOPS with lower, average and upper baseline (predict command rendering) - no future charting
[nmon_iops_full_baseline(2)]
args= hostname,statsmode
definition = tstats sum("DISKXFER.value") AS "DISKXFER.value" from datamodel=NMON_Data_DISKXFER where (nodename = DISKXFER) (DISKXFER.hostname=$hostname$)\
groupby _time, "DISKXFER.hostname", "DISKXFER.date_wday", "DISKXFER.local_time" prestats=true span=1m\
| bucket _time span=1m | stats dedup_splitvals=t sum("DISKXFER.value") AS "DISKXFER.value" by _time, "DISKXFER.hostname", "DISKXFER.date_wday", "DISKXFER.local_time"\
| rename DISKXFER.* AS *\
| bucket _time span=5m | stats avg(value) AS value by _time, hostname\
| eval date_wday=if(isnull(date_wday), lower(strftime('_time', "%A")), date_wday)\
| eval local_time=if(isnull(local_time), strftime('_time', "%H%M"), local_time)\
| lookup nmon_baseline_DISKXFER date_wday,local_time,hostname\
| timechart `baseline_span` $statsmode$(value) AS disk_iops,\
avg(lower_baseline_avg_disk_iops) AS lower, avg(baseline_avg_disk_iops) AS predicted, avg(upper_baseline_avg_disk_iops) AS upper\
| eval _lower = "lower" | eval _predicted = "predicted" | eval _upper = "upper"
iseval = 0
